{
  "cells": [
    {
      "metadata": {
        "_uuid": "37fd1fed10a0d3943a4f511b77e31b73d4934f18"
      },
      "cell_type": "markdown",
      "source": "# Using a Keras Convolutional Neural Network for classifying Flower Images"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5bb39a33e85142d77a0eaf1f91542a469b5314fd"
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b00b29f5cbd7623a2bbff66b8b680a1258200ba2"
      },
      "cell_type": "code",
      "source": "from glob import glob\nimport cv2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "552fec21a33a829a48c1827c6cfcb402e2e2058c"
      },
      "cell_type": "markdown",
      "source": "## Importing images using OpenCV and Glob"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "07207a0af8e00dde12f5841fd1e78f1d947fbeb1"
      },
      "cell_type": "code",
      "source": "import os",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0879a41a779486818a977a9b41efa1f0f7c65854",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "os.listdir(\"../input/flowers/flowers/\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a46a03211f1cb583d3f75d453f1e35084afe902c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "daisy_path = glob(\"../input/flowers/flowers/daisy/*jpg\", recursive=True)\ndandi_path = glob(\"../input/flowers/flowers/dandelion/*jpg\", recursive=True)\nrose_path = glob(\"../input/flowers/flowers/rose/*jpg\", recursive=True)\nsunflower_path = glob(\"../input/flowers/flowers/sunflower/*jpg\", recursive=True)\ntulip_path = glob(\"../input/flowers/flowers/tulip/*jpg\", recursive=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "62ca018454586a48cd79f32f37630ea3106bf072"
      },
      "cell_type": "markdown",
      "source": "1. Above, we have defined the paths to the flowers dataset images.\n2. In the below step, we read image files into the dataset using OpenCV (`cv2`)"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "51cba67ee890d1cde90bdfdb9871dc8a060aced0"
      },
      "cell_type": "code",
      "source": "daisy_images = [cv2.imread(file) for file in daisy_path]\ndandi_images = [cv2.imread(file) for file in dandi_path]\nrose_images = [cv2.imread(file) for file in rose_path]\nsunflower_images = [cv2.imread(file) for file in sunflower_path]\ntulip_images = [cv2.imread(file) for file in tulip_path]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8601816793c951e0c6cc09eaa17a099b9bc2c722"
      },
      "cell_type": "markdown",
      "source": "Print 4 random images from the daisy_images set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28191696825ac112c3cc3480649fa30ff431325f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Shapes of different daisy images and what they look like\\n\")\ndef print_image(img):\n    plt.figure()\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.title(img.shape)\n    plt.show()\n\nfor num in np.random.choice(daisy_images, size = 4):\n    print_image(num)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "906728d65edc86cebbc2d1f6617c65f63733e9e9"
      },
      "cell_type": "code",
      "source": "def resize_image(image):\n    return cv2.resize(image, (320,320))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "337bf5320074623935aa465b0889405a1e562b40"
      },
      "cell_type": "code",
      "source": "reshaped_daisy = [resize_image(img) for img in daisy_images]\nreshaped_dandi = [resize_image(img) for img in dandi_images]\nreshaped_rose = [resize_image(img) for img in rose_images]\nreshaped_sunflower = [resize_image(img) for img in sunflower_images]\nreshaped_tulip = [resize_image(img) for img in tulip_images]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a6ccf9983632519317797944887abb206de29543"
      },
      "cell_type": "code",
      "source": "num_daisy, num_dandi, num_rose, num_sunflower, num_tulip = len(reshaped_daisy), len(reshaped_dandi), len(reshaped_rose), len(reshaped_sunflower), len(reshaped_tulip)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "892ad60b474cbd34b1f1c48bfe5cf68383150b36"
      },
      "cell_type": "code",
      "source": "labels_daisy = ['daisy']*num_daisy\nlabels_dandi = ['dandi']*num_dandi\nlabels_rose = ['rose']*num_rose\nlabels_sunflower = ['sunflower']*num_sunflower\nlabels_tulip = ['tulip']*num_tulip",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "68fe0d7c582892cc42b60e9d2694204b33c73ed9"
      },
      "cell_type": "code",
      "source": "labels = np.concatenate((labels_daisy, labels_dandi, labels_rose, labels_sunflower, labels_tulip))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "848779463b0308b509cb131e5fb637286b5fdd11"
      },
      "cell_type": "code",
      "source": "images = np.concatenate((reshaped_daisy, reshaped_dandi, reshaped_rose, reshaped_sunflower, reshaped_tulip))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f95e63933f699481b86ea61790d3ba1231be7de5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Images data shape:\", images.shape)\nprint(\"Labels data shape:\", labels.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "69ab43d1e1d71a705b4c17199790746bcc62cd63"
      },
      "cell_type": "code",
      "source": "n_classes = len(np.unique(labels))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0965cec9597821f09b20b5a21c57707f9973948f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Dropout, BatchNormalization, Flatten\nfrom keras.regularizers import l1_l2\nfrom keras.optimizers import Adam",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7cceed0794270c3e61aa392f3464c77c1be026dc"
      },
      "cell_type": "code",
      "source": "#Params\n\nn_hidden = 50\nl1, l2 = 0.15, 0.15\ndropoutpc = 0.25",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5fbb09171582a771ddfad6ae6c02406a0cb3769",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "flw_model = Sequential([\n    Conv2D(filters=10,kernel_size=(2,2), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same', input_shape = (320,320,3), data_format='channels_last'),\n    MaxPool2D((2,2)),\n    Conv2D(filters=20,kernel_size=(2,2), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same'),\n    Conv2D(filters=20,kernel_size=(4,4), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same'),\n    MaxPool2D((3,3)),\n    Conv2D(filters=30,kernel_size=(2,2), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same'),\n    Conv2D(filters=30,kernel_size=(4,4), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same'),\n    MaxPool2D((2,2)),\n    Conv2D(filters=40,kernel_size=(2,2), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same'),\n    Conv2D(filters=40,kernel_size=(4,4), activation='relu', kernel_regularizer=l1_l2(l1, l2), strides=1, padding='same'),\n    MaxPool2D((2,2)),\n    Dense(n_hidden),\n    Flatten(),\n    BatchNormalization(),\n    Dropout(dropoutpc),\n    Dense(n_classes, activation=\"softmax\")    \n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37995a9631c2726e3e4d3ee24c734125b39bb24c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "flw_model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "789b91540a5a62ceedd12b14d30f4bcb312c91d6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84217052faeb6fd4e09e0190d648cf8ef90dc82c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "label_dummies = pd.get_dummies(labels).as_matrix()\nprint(label_dummies.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df041fca9395978f304cc1c0dad8e4a2816de6ff",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "trainX, testX, trainY_cat, testY_cat = train_test_split(images, labels, test_size = 0.2)\ntrainY = pd.get_dummies(trainY_cat).as_matrix()\ntestY = pd.get_dummies(testY_cat).as_matrix()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5f0436400c6821f311a18f84acd8732dc8a5f873"
      },
      "cell_type": "code",
      "source": "batchsize = 16\nepochs = 32\nlr = 1e-4\ndecay = 0.1 * lr\n\nopt = Adam(lr, decay)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c06cc5bfe6f3034b4250f5e5e4689e0e38c7a235"
      },
      "cell_type": "code",
      "source": "flw_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['acc'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b23a27ae6ad79f6a6462aa1e6d5cce34b5c1372b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "history = flw_model.fit(x = trainX, y= trainY, batch_size = batchsize, epochs = epochs, validation_split= 0.2, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ef03fe1873108064d875a37f9567069e6af5e0f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pd.DataFrame(history.history)[['loss', 'val_loss']].plot(figsize = (16,4), title = \"Loss\")\npd.DataFrame(history.history)[['acc', 'val_acc']].plot(figsize = (16,4), title = \"Accuracy\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1ee752ca0f6f00e96907eed1cf90eaf3744f9b8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_pred = flw_model.predict_classes(testX).reshape((len(test_pred),1))\nprint(test_pred.shape)\n\ntestY_labels = np.reshape(np.argmax(testY, axis=1), (-1,1))\n\nprecision_score(testY_labels, test_pred, average='macro'), recall_score(testY_labels, test_pred, average='macro'), f1_score(testY_labels, test_pred, average='macro')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9a5b3725390b1dc86618027665d19e76ef69cef0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}